{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def softmax(m):\n",
    "    x,y=np.shape(m)\n",
    "    #生成一个10*10 的随机二维数组，再加上1000  \n",
    "    #axis=1 表示在二维数组中沿着横轴进行取最大值的操作  \n",
    "    #m_row_max = m.max(axis = 1)   \n",
    "    #每一行减去自己本行最大的数字，用到broadcast，reshape  \n",
    "    #不这么处理会导致INF  \n",
    "    #m = m - m_row_max.reshape(x,1)\n",
    "\n",
    "    #计算e的指数次幂  \n",
    "    m_exp = np.exp(m)  \n",
    "\n",
    "    #对每一行进行一次求和操作  \n",
    "    m_exp_row_sum = m_exp.sum(axis=1).reshape(x,1)\n",
    "    #每一行的原始数据m_exp / 每一行的和  \n",
    "    softmax_ = m_exp / m_exp_row_sum  \n",
    "    return (softmax_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "m = np.array(([1.0,2.0,3.0],[3.0,2.0,1.0]))\n",
    "print (np.sum(softmax(m),axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(value):\n",
    "    n_values = np.max(value)+1\n",
    "    return np.eye(n_values)[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "m = np.array([1,2,3])\n",
    "print (one_hot(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print (0*float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y: real a: pred\n",
    "def get_loss(y,a):\n",
    "    e = -np.sum(y.dot(np.log(a.T)))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235.880889948\n",
      "235.918609551\n",
      "0.11\n",
      "235.763856832\n",
      "235.801574094\n",
      "0.08\n",
      "234.125223814\n",
      "234.162938898\n",
      "0.1\n",
      "235.89484677\n",
      "235.932561501\n",
      "0.07\n",
      "234.855130255\n",
      "234.892843788\n",
      "0.08\n",
      "234.067588049\n",
      "234.105302362\n",
      "0.1\n",
      "232.50796278\n",
      "232.545676989\n",
      "0.09\n",
      "231.748714148\n",
      "231.786429201\n",
      "0.11\n",
      "232.441578407\n",
      "232.479295666\n",
      "0.17\n",
      "234.034515927\n",
      "234.072237044\n",
      "0.19\n",
      "233.908351673\n",
      "233.946077384\n",
      "0.09\n",
      "233.89171854\n",
      "233.929447643\n",
      "0.24\n",
      "232.331439115\n",
      "232.369173845\n",
      "0.3\n",
      "232.959662241\n",
      "232.99740359\n",
      "0.26\n",
      "232.659272925\n",
      "232.697024066\n",
      "0.28\n",
      "230.74207858\n",
      "230.779838993\n",
      "0.36\n",
      "234.237937227\n",
      "234.275706837\n",
      "0.31\n",
      "229.055584421\n",
      "229.093366996\n",
      "0.49\n",
      "231.997305503\n",
      "232.035100447\n",
      "0.34\n",
      "231.523979369\n",
      "231.561789087\n",
      "0.35\n",
      "230.450187864\n",
      "230.488015759\n",
      "0.43\n",
      "232.785705004\n",
      "232.823549218\n",
      "0.41\n",
      "229.655020908\n",
      "229.69288695\n",
      "0.53\n",
      "232.318710165\n",
      "232.356596144\n",
      "0.43\n",
      "230.512344974\n",
      "230.55025049\n",
      "0.54\n",
      "232.20770348\n",
      "232.245631393\n",
      "0.49\n",
      "232.716151215\n",
      "232.754108301\n",
      "0.46\n",
      "234.471782938\n",
      "234.509767644\n",
      "0.44\n",
      "230.636563655\n",
      "230.67458032\n",
      "0.64\n",
      "233.508391074\n",
      "233.546440225\n",
      "0.48\n",
      "231.220383052\n",
      "231.258467622\n",
      "0.58\n",
      "231.902717811\n",
      "231.940833294\n",
      "0.62\n",
      "232.581861732\n",
      "232.620013156\n",
      "0.59\n",
      "234.384299953\n",
      "234.422494717\n",
      "0.59\n",
      "233.207440384\n",
      "233.24567759\n",
      "0.59\n",
      "235.560836448\n",
      "235.599119918\n",
      "0.59\n",
      "233.136175853\n",
      "233.174506082\n",
      "0.6\n",
      "236.628771864\n",
      "236.667153136\n",
      "0.59\n",
      "236.325899705\n",
      "236.364332691\n",
      "0.73\n",
      "235.802284309\n",
      "235.840772448\n",
      "0.69\n",
      "239.251216878\n",
      "239.289762381\n",
      "0.72\n",
      "240.60518907\n",
      "240.643802724\n",
      "0.72\n",
      "240.395335421\n",
      "240.434010753\n",
      "0.7\n",
      "236.769019823\n",
      "236.807770571\n",
      "0.73\n",
      "245.981082832\n",
      "246.019904954\n",
      "0.68\n",
      "249.08978541\n",
      "249.128669062\n",
      "0.75\n",
      "252.572816659\n",
      "252.611786453\n",
      "0.59\n",
      "248.247317375\n",
      "248.286356875\n",
      "0.8\n",
      "248.658639738\n",
      "248.697758458\n",
      "0.74\n",
      "254.334343851\n",
      "254.373544155\n",
      "0.69\n",
      "256.28595005\n",
      "256.325237359\n",
      "0.65\n",
      "264.167659191\n",
      "264.207032608\n",
      "0.65\n",
      "262.433649018\n",
      "262.473095559\n",
      "0.77\n",
      "270.810041584\n",
      "270.849575212\n",
      "0.76\n",
      "278.315800851\n",
      "278.355422035\n",
      "0.76\n",
      "280.270286079\n",
      "280.30999748\n",
      "0.71\n",
      "278.076891781\n",
      "278.116693411\n",
      "0.71\n",
      "266.843825752\n",
      "266.883713787\n",
      "0.69\n",
      "279.849961344\n",
      "279.889939603\n",
      "0.8\n",
      "286.48290365\n",
      "286.522969547\n",
      "0.76\n",
      "310.673308757\n",
      "310.713468851\n",
      "0.78\n",
      "306.237105921\n",
      "306.277356221\n",
      "0.82\n",
      "303.109270727\n",
      "303.149608934\n",
      "0.75\n",
      "307.236142249\n",
      "307.276575072\n",
      "0.81\n",
      "308.436634543\n",
      "308.477166925\n",
      "0.8\n",
      "312.218622258\n",
      "312.259237993\n",
      "0.87\n",
      "318.652463126\n",
      "318.693180904\n",
      "0.82\n",
      "305.325376021\n",
      "305.366187143\n",
      "0.83\n",
      "309.021111648\n",
      "309.062023986\n",
      "0.71\n",
      "343.327729691\n",
      "343.368722025\n",
      "0.74\n",
      "333.184329474\n",
      "333.225395915\n",
      "0.77\n",
      "318.418194231\n",
      "318.459345886\n",
      "0.87\n",
      "310.371963739\n",
      "310.413204479\n",
      "0.74\n",
      "313.745232549\n",
      "313.786555681\n",
      "0.79\n",
      "330.999194318\n",
      "331.040596635\n",
      "0.8\n",
      "351.538231289\n",
      "351.57972025\n",
      "0.83\n",
      "343.630225736\n",
      "343.671795692\n",
      "0.73\n",
      "349.5918219\n",
      "349.633475191\n",
      "0.8\n",
      "393.547153938\n",
      "393.588886221\n",
      "0.77\n",
      "404.742744978\n",
      "404.784527966\n",
      "0.76\n",
      "417.40254984\n",
      "417.444385073\n",
      "0.87\n",
      "377.391928396\n",
      "377.433836094\n",
      "0.73\n",
      "386.61095097\n",
      "386.652919507\n",
      "0.75\n",
      "392.432319593\n",
      "392.474344832\n",
      "0.81\n",
      "401.911369472\n",
      "401.95346561\n",
      "0.75\n",
      "461.030137184\n",
      "461.072282861\n",
      "0.85\n",
      "427.519034541\n",
      "427.561234599\n",
      "0.79\n",
      "391.532034989\n",
      "391.574278107\n",
      "0.65\n",
      "401.236729432\n",
      "401.279003458\n",
      "0.75\n",
      "442.809290317\n",
      "442.851625919\n",
      "0.79\n",
      "424.061012923\n",
      "424.103395829\n",
      "0.84\n",
      "404.669178861\n",
      "404.71162897\n",
      "0.86\n",
      "408.44782735\n",
      "408.49035304\n",
      "0.81\n",
      "433.437242098\n",
      "433.479824121\n",
      "0.8\n",
      "466.013128543\n",
      "466.055755909\n",
      "0.88\n",
      "420.978286552\n",
      "421.020976654\n",
      "0.77\n",
      "443.48445285\n",
      "443.52719671\n",
      "0.84\n",
      "472.454730496\n",
      "472.497538286\n",
      "0.78\n",
      "451.846376233\n",
      "451.889219246\n",
      "0.86\n",
      "449.78029471\n",
      "449.823194402\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definition of functions and parameters\n",
    "\n",
    "# NEPOCHis batch size; D_in is input dimension;\n",
    "# H1 is hidden layer1 dimension; \n",
    "# H2 is hidden layer2 dimension\n",
    "# D_out is output dimension.\n",
    "D_in = 784\n",
    "D_out =10\n",
    "EPOCH = 100\n",
    "H1 = 300\n",
    "H2 = 100\n",
    "\n",
    "learning_rate = 0.1\n",
    "lam = 0.0005\n",
    "\n",
    "# Read all data from .pkl\n",
    "(train_images, train_labels, test_images, test_labels) = pickle.load(open('./mnist_data/data.pkl', 'rb'),\n",
    "                                                                     encoding='latin1')\n",
    "\n",
    "### 1. Data preprocessing: normalize all pixels to [0,1) by dividing 256\n",
    "train_images = train_images/256\n",
    "test_images = test_images/256\n",
    "\n",
    "### 2. Weight initialization: Xavier\n",
    "w1 = (np.random.rand(D_in,H1)-0.5)*(6**0.5)/(H1+D_in)**0.5\n",
    "w2 = (np.random.rand(H1,H2)-0.5)*(6**0.5)/(H2+H1)**0.5\n",
    "w3 = (np.random.rand(H2,D_out)-0.5)*(6**0.5)/(H2+D_out)**0.5\n",
    "# bais\n",
    "b1 = (np.random.rand(H1,1)-0.5)*(6**0.5)/(H1+1)**0.5\n",
    "b2 = (np.random.rand(H2,1)-0.5)*(6**0.5)/(H2+1)**0.5\n",
    "b3 = (np.random.rand(D_out,1)-0.5)*(6**0.5)/(D_out+1)**0.5\n",
    "\n",
    "\n",
    "### 3. training of neural network\n",
    "loss = np.zeros((EPOCH))\n",
    "accuracy = np.zeros((EPOCH))\n",
    "\n",
    "accuracy= []\n",
    "n = int(len(train_images)/EPOCH)\n",
    "for epoch in range(0, n):\n",
    "    #if epoch > 50:\n",
    "        #learning_rate = 0.01\n",
    "    # create input and output\n",
    "    x = train_images[epoch*EPOCH:epoch*EPOCH+EPOCH]\n",
    "    y = train_labels[epoch*EPOCH:epoch*EPOCH+EPOCH]\n",
    "    y = one_hot(y)\n",
    "    \n",
    "    # Forward propagation\n",
    "    h1 = (x.dot(w1).T+b1).T\n",
    "    # perform relu transform\n",
    "    h1 = np.maximum(h1,0)\n",
    "    \n",
    "    h2 = (h1.dot(w2).T+b2).T\n",
    "    h2 = np.maximum(h2,0)\n",
    "    \n",
    "    h3 = (h2.dot(w3).T+b3).T\n",
    "    #print('%d:'%epoch+'before'+'*'*100)\n",
    "    #print(h3)\n",
    "    h3 = softmax(h3)\n",
    "    #print('softmax'+'*'*100)\n",
    "    #print(h3)\n",
    "    \n",
    "    #print('softmax_sum'+'*'*100)\n",
    "    #print(np.sum(h3,axis =1))\n",
    "    # compute loss function\n",
    "    \n",
    "    e = -np.sum(y.dot(np.log(h3.T)))\n",
    "    print (e/EPOCH)\n",
    "    l = e/EPOCH + 0.5*lam*(np.sum(np.square(w1)) + np.sum(np.square(w2))+ np.sum(np.square(w3)))\n",
    "    print(l)\n",
    "    # Back propagation\n",
    "    k3 = h3-y\n",
    "    h2_f = np.where(h2 > 0, 1, 0)\n",
    "    k2 = k3.dot(w3.T)*h2_f\n",
    "    h1_f = np.where(h1>0,1,0)\n",
    "    k1 = k2.dot(w2.T)*h1_f\n",
    "    \n",
    "    # Gradient update\n",
    "    w3 = w3 - learning_rate*h2.T.dot(k3)/EPOCH - learning_rate*lam*w3\n",
    "    b3 = b3 - (learning_rate*np.sum(k3,axis=0)/EPOCH).reshape(D_out,1)\n",
    "    w2 = w2 -learning_rate*h1.T.dot(k2)/EPOCH - learning_rate*lam*w2\n",
    "    b2 = b2 - (learning_rate*np.sum(k2,axis=0)/EPOCH).reshape(H2,1)\n",
    "    w1 = w1 - learning_rate*x.T.dot(k1)/EPOCH - learning_rate*lam*w1\n",
    "    b1 = b1 - (learning_rate*np.sum(k1,axis=0)/EPOCH).reshape(H1,1)\n",
    "    \n",
    "    # Testing for accuracy\n",
    "    same_num = 0\n",
    "    a = np.zeros(np.shape(h3))\n",
    "    for row in range(np.shape(h3)[0]):\n",
    "        x = np.argmax(h3[row])\n",
    "        a[row][x] = 1\n",
    "        if y[row][x] ==1:\n",
    "            same_num = same_num +1\n",
    "    print(same_num/EPOCH)\n",
    "    \n",
    "    accuracy.append(same_num/EPOCH)\n",
    "\n",
    "### 4. Plot\n",
    "# for example\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "fig.suptitle('accuracy') \n",
    "ax1 = plt.subplot(111)\n",
    "#ax1.plot(......)\n",
    "plt.plot(range(n),accuracy,label='accuracy')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.tight_layout()\n",
    "plt.savefig('figure.pdf', dbi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999900000001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list([0.04779658,0.0577835 ,0.11268435 ,0.0624714,0.11941648,0.15709186\n",
    "   ,0.11230297,0.15308466,0.10943788,0.06793031]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16666667  0.33333333  0.5       ]\n",
      " [ 0.5         0.33333333  0.16666667]]\n"
     ]
    }
   ],
   "source": [
    "m = np.array(([1.0,2.0,3.0],[3.0,2.0,1.0]))\n",
    "# 0 : column\n",
    "for i in range(2):\n",
    "    m[i]= m[i]/np.sum(m[i])\n",
    "print (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [1, 0, 3]\n",
    "n_values = np.max(values) + 1\n",
    "np.eye(n_values)[values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  4.  9.]\n",
      " [ 9.  4.  1.]]\n",
      "[[  1.   2.   3.]\n",
      " [ 30.  20.  10.]]\n",
      "[ 4.  4.  4.]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1,10])\n",
    "a = np.array(([1.0,2.0,3.0],[3.0,2.0,1.0]))\n",
    "b = np.array(([1.0,2.0,3.0],[3.0,2.0,1.0]))\n",
    "print(a*b)\n",
    "print (a*y.reshape(2,1))\n",
    "print (np.sum(a,axis =0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y,a):\n",
    "    return -np.sum(y.dot(np.log(a.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (3,2) not aligned: 2 (dim 0) != 3 (dim 0)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-143514d462e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-087e9c05a0e9>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(y, a)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,) and (3,2) not aligned: 2 (dim 0) != 3 (dim 0)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(loss(y,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30506412.605\n",
      "1 25706430.4036\n",
      "2 25397791.8236\n",
      "3 25363822.8186\n",
      "4 23255394.3185\n",
      "5 18511286.4303\n",
      "6 12741474.0396\n",
      "7 7814574.22985\n",
      "8 4568377.68082\n",
      "9 2697825.92125\n",
      "10 1692916.39168\n",
      "11 1149064.18796\n",
      "12 843249.468185\n",
      "13 658104.786158\n",
      "14 536318.999883\n",
      "15 449611.135241\n",
      "16 383963.301642\n",
      "17 331888.40688\n",
      "18 289358.185618\n",
      "19 253921.18117\n",
      "20 223984.960207\n",
      "21 198457.022805\n",
      "22 176500.412102\n",
      "23 157485.343088\n",
      "24 140946.815001\n",
      "25 126510.921524\n",
      "26 113885.411122\n",
      "27 102769.485296\n",
      "28 92949.6814643\n",
      "29 84249.0629755\n",
      "30 76519.6922045\n",
      "31 69628.8460272\n",
      "32 63479.206377\n",
      "33 57974.2259434\n",
      "34 53039.914146\n",
      "35 48606.3186616\n",
      "36 44612.6970216\n",
      "37 41005.9876713\n",
      "38 37744.8197075\n",
      "39 34788.2867932\n",
      "40 32102.637708\n",
      "41 29658.3840603\n",
      "42 27432.0948063\n",
      "43 25400.1338184\n",
      "44 23543.4645926\n",
      "45 21843.9823903\n",
      "46 20286.7718686\n",
      "47 18857.5875403\n",
      "48 17544.5688456\n",
      "49 16336.3325027\n",
      "50 15223.7649789\n",
      "51 14198.5166504\n",
      "52 13251.9184142\n",
      "53 12377.4054155\n",
      "54 11568.9612936\n",
      "55 10820.8869233\n",
      "56 10127.5483747\n",
      "57 9484.11625597\n",
      "58 8887.01162937\n",
      "59 8332.32454241\n",
      "60 7817.11193774\n",
      "61 7337.79923642\n",
      "62 6891.51589296\n",
      "63 6475.55668066\n",
      "64 6087.65569181\n",
      "65 5725.60242071\n",
      "66 5387.62041418\n",
      "67 5072.1633433\n",
      "68 4777.21773596\n",
      "69 4501.23034443\n",
      "70 4242.9110974\n",
      "71 4000.97750334\n",
      "72 3774.28775474\n",
      "73 3561.70928393\n",
      "74 3362.23624819\n",
      "75 3175.05656207\n",
      "76 2999.29827529\n",
      "77 2834.20406314\n",
      "78 2679.05318028\n",
      "79 2533.16887029\n",
      "80 2396.01604565\n",
      "81 2267.1148425\n",
      "82 2145.75872891\n",
      "83 2031.44096679\n",
      "84 1923.73343956\n",
      "85 1822.22168959\n",
      "86 1726.53654696\n",
      "87 1636.26803931\n",
      "88 1551.14464545\n",
      "89 1470.75284047\n",
      "90 1394.8934281\n",
      "91 1323.2530967\n",
      "92 1255.57348991\n",
      "93 1191.60029837\n",
      "94 1131.14761125\n",
      "95 1074.00206957\n",
      "96 1019.93950241\n",
      "97 968.77154743\n",
      "98 920.368068448\n",
      "99 874.522807884\n",
      "100 831.12115172\n",
      "101 790.014171885\n",
      "102 751.073290448\n",
      "103 714.181382188\n",
      "104 679.218549612\n",
      "105 646.075806082\n",
      "106 614.695626805\n",
      "107 584.931888972\n",
      "108 556.701852055\n",
      "109 529.907520048\n",
      "110 504.477774852\n",
      "111 480.344875173\n",
      "112 457.42941777\n",
      "113 435.67110358\n",
      "114 414.999252434\n",
      "115 395.359804821\n",
      "116 376.704539515\n",
      "117 358.976708699\n",
      "118 342.128092364\n",
      "119 326.118689261\n",
      "120 310.889985877\n",
      "121 296.410394841\n",
      "122 282.636092772\n",
      "123 269.530269733\n",
      "124 257.058953337\n",
      "125 245.195747492\n",
      "126 233.908923578\n",
      "127 223.158835637\n",
      "128 212.922579515\n",
      "129 203.17657523\n",
      "130 193.897674322\n",
      "131 185.058334577\n",
      "132 176.639470416\n",
      "133 168.622085102\n",
      "134 160.986516251\n",
      "135 153.704532675\n",
      "136 146.763324682\n",
      "137 140.149950413\n",
      "138 133.846447778\n",
      "139 127.836248881\n",
      "140 122.105703733\n",
      "141 116.642701717\n",
      "142 111.432365334\n",
      "143 106.462230141\n",
      "144 101.720094282\n",
      "145 97.1976174622\n",
      "146 92.8830280799\n",
      "147 88.7658190988\n",
      "148 84.8369084171\n",
      "149 81.0893519552\n",
      "150 77.5142822823\n",
      "151 74.1045006552\n",
      "152 70.8484754994\n",
      "153 67.7402666198\n",
      "154 64.7732910639\n",
      "155 61.9402216525\n",
      "156 59.2348687919\n",
      "157 56.6507553791\n",
      "158 54.1825801065\n",
      "159 51.8253689823\n",
      "160 49.5726404444\n",
      "161 47.4205931084\n",
      "162 45.3643551803\n",
      "163 43.4005018669\n",
      "164 41.5235198084\n",
      "165 39.7292888472\n",
      "166 38.0146563827\n",
      "167 36.3762965373\n",
      "168 34.8108625654\n",
      "169 33.3133395192\n",
      "170 31.8823827142\n",
      "171 30.5139241175\n",
      "172 29.2056112533\n",
      "173 27.954635591\n",
      "174 26.7581810119\n",
      "175 25.6147956212\n",
      "176 24.520843458\n",
      "177 23.4746613436\n",
      "178 22.4747929701\n",
      "179 21.5177893116\n",
      "180 20.6021558049\n",
      "181 19.726401643\n",
      "182 18.8884763585\n",
      "183 18.0868940882\n",
      "184 17.3200615847\n",
      "185 16.5864387667\n",
      "186 15.884529235\n",
      "187 15.212733021\n",
      "188 14.5700679151\n",
      "189 13.9549495\n",
      "190 13.3661025487\n",
      "191 12.8026124673\n",
      "192 12.2634425514\n",
      "193 11.7472083571\n",
      "194 11.253014156\n",
      "195 10.7800009873\n",
      "196 10.3273213891\n",
      "197 9.89392038343\n",
      "198 9.47889542604\n",
      "199 9.0816923061\n",
      "200 8.7014494883\n",
      "201 8.3371803077\n",
      "202 7.98838120954\n",
      "203 7.65440741055\n",
      "204 7.33460307795\n",
      "205 7.02839704359\n",
      "206 6.73537384016\n",
      "207 6.45457712832\n",
      "208 6.18555140084\n",
      "209 5.92789376602\n",
      "210 5.68111992789\n",
      "211 5.44480394828\n",
      "212 5.21849411113\n",
      "213 5.00166817539\n",
      "214 4.79392573945\n",
      "215 4.59501884435\n",
      "216 4.40447244809\n",
      "217 4.22185153944\n",
      "218 4.04685948962\n",
      "219 3.87924233238\n",
      "220 3.71868132559\n",
      "221 3.56482351995\n",
      "222 3.41741058466\n",
      "223 3.27616783235\n",
      "224 3.1409269518\n",
      "225 3.01124193759\n",
      "226 2.88696364205\n",
      "227 2.76791505192\n",
      "228 2.65379004064\n",
      "229 2.5444160512\n",
      "230 2.43957963366\n",
      "231 2.33912761527\n",
      "232 2.2428913728\n",
      "233 2.15064382904\n",
      "234 2.06221190225\n",
      "235 1.97743995271\n",
      "236 1.896196243\n",
      "237 1.8183470979\n",
      "238 1.74369324821\n",
      "239 1.67213822683\n",
      "240 1.60355530344\n",
      "241 1.53782250985\n",
      "242 1.47481070025\n",
      "243 1.41438227988\n",
      "244 1.35644962483\n",
      "245 1.30090444313\n",
      "246 1.24765970729\n",
      "247 1.19662026058\n",
      "248 1.14770354798\n",
      "249 1.10078025421\n",
      "250 1.0558088714\n",
      "251 1.0126805829\n",
      "252 0.971324497264\n",
      "253 0.931674296201\n",
      "254 0.893647202614\n",
      "255 0.857196811903\n",
      "256 0.822234793253\n",
      "257 0.788708115748\n",
      "258 0.756575140623\n",
      "259 0.725747015548\n",
      "260 0.696181824293\n",
      "261 0.667831968353\n",
      "262 0.640657495634\n",
      "263 0.614586170876\n",
      "264 0.589579675955\n",
      "265 0.565604308189\n",
      "266 0.542617613483\n",
      "267 0.520560588426\n",
      "268 0.499412268452\n",
      "269 0.479128406071\n",
      "270 0.459667989848\n",
      "271 0.441004213717\n",
      "272 0.423101057078\n",
      "273 0.405932230586\n",
      "274 0.389467155252\n",
      "275 0.373671436835\n",
      "276 0.358524228976\n",
      "277 0.343990966341\n",
      "278 0.330050843438\n",
      "279 0.316676828849\n",
      "280 0.303851875204\n",
      "281 0.291550591407\n",
      "282 0.279750514663\n",
      "283 0.268428800203\n",
      "284 0.257565367326\n",
      "285 0.247143669221\n",
      "286 0.237146490963\n",
      "287 0.227557387187\n",
      "288 0.218359834398\n",
      "289 0.209536852776\n",
      "290 0.201070773455\n",
      "291 0.192947745717\n",
      "292 0.185152978365\n",
      "293 0.177674649862\n",
      "294 0.170501863691\n",
      "295 0.163619281559\n",
      "296 0.157019011388\n",
      "297 0.15068639053\n",
      "298 0.144607527241\n",
      "299 0.13877455526\n",
      "300 0.133179262963\n",
      "301 0.127810441639\n",
      "302 0.122658094739\n",
      "303 0.117714915944\n",
      "304 0.112973903809\n",
      "305 0.108422858488\n",
      "306 0.104056492641\n",
      "307 0.0998665382867\n",
      "308 0.095845127946\n",
      "309 0.0919869721585\n",
      "310 0.0882852729964\n",
      "311 0.0847344593964\n",
      "312 0.0813257267273\n",
      "313 0.0780549492588\n",
      "314 0.0749159679774\n",
      "315 0.0719034687418\n",
      "316 0.0690126392732\n",
      "317 0.0662390007698\n",
      "318 0.0635783271238\n",
      "319 0.0610237433868\n",
      "320 0.0585719518921\n",
      "321 0.0562187936264\n",
      "322 0.0539606926359\n",
      "323 0.0517941221442\n",
      "324 0.0497148044098\n",
      "325 0.0477201199995\n",
      "326 0.0458049656722\n",
      "327 0.0439665559869\n",
      "328 0.0422026040336\n",
      "329 0.0405094800035\n",
      "330 0.0388845560818\n",
      "331 0.037325633825\n",
      "332 0.0358295769847\n",
      "333 0.0343931504228\n",
      "334 0.0330143926289\n",
      "335 0.0316911238959\n",
      "336 0.0304210520696\n",
      "337 0.0292021041458\n",
      "338 0.0280324897957\n",
      "339 0.0269098705329\n",
      "340 0.025831951037\n",
      "341 0.0247975220204\n",
      "342 0.0238044264072\n",
      "343 0.0228513621462\n",
      "344 0.0219366214654\n",
      "345 0.0210590464534\n",
      "346 0.0202164400806\n",
      "347 0.0194073865461\n",
      "348 0.0186309843173\n",
      "349 0.0178856196734\n",
      "350 0.0171704049297\n",
      "351 0.0164836663251\n",
      "352 0.015824880393\n",
      "353 0.0151921504161\n",
      "354 0.0145848250487\n",
      "355 0.0140018109736\n",
      "356 0.0134421372728\n",
      "357 0.0129048755425\n",
      "358 0.0123892627882\n",
      "359 0.0118945410487\n",
      "360 0.0114193043098\n",
      "361 0.0109631267331\n",
      "362 0.0105252427163\n",
      "363 0.0101049637002\n",
      "364 0.00970143368758\n",
      "365 0.00931418281741\n",
      "366 0.00894245759417\n",
      "367 0.00858551561125\n",
      "368 0.00824277711637\n",
      "369 0.00791376999404\n",
      "370 0.00759808058178\n",
      "371 0.00729497103093\n",
      "372 0.0070040930784\n",
      "373 0.00672471614026\n",
      "374 0.0064564639596\n",
      "375 0.0061989523882\n",
      "376 0.00595173504492\n",
      "377 0.00571439360641\n",
      "378 0.00548660255452\n",
      "379 0.00526794828761\n",
      "380 0.00505793847989\n",
      "381 0.00485633469825\n",
      "382 0.00466280617511\n",
      "383 0.00447698062364\n",
      "384 0.00429860653895\n",
      "385 0.00412739744227\n",
      "386 0.00396296283851\n",
      "387 0.00380508839137\n",
      "388 0.00365354734813\n",
      "389 0.00350801683793\n",
      "390 0.00336829541706\n",
      "391 0.00323426767651\n",
      "392 0.0031055286902\n",
      "393 0.00298188727155\n",
      "394 0.00286316970761\n",
      "395 0.00274920761504\n",
      "396 0.00263977583787\n",
      "397 0.00253473750285\n",
      "398 0.00243387796572\n",
      "399 0.00233705339153\n",
      "400 0.0022440752497\n",
      "401 0.00215478572169\n",
      "402 0.00206905587239\n",
      "403 0.001986770118\n",
      "404 0.00190776566774\n",
      "405 0.0018318872445\n",
      "406 0.00175905001252\n",
      "407 0.00168909874934\n",
      "408 0.0016219307459\n",
      "409 0.00155746065112\n",
      "410 0.0014955672105\n",
      "411 0.00143610871452\n",
      "412 0.00137902740997\n",
      "413 0.00132422894044\n",
      "414 0.00127161050603\n",
      "415 0.00122107085603\n",
      "416 0.00117256745218\n",
      "417 0.00112598379886\n",
      "418 0.00108125386043\n",
      "419 0.00103830394397\n",
      "420 0.000997060219307\n",
      "421 0.000957454961396\n",
      "422 0.000919437013087\n",
      "423 0.000882918595976\n",
      "424 0.000847857368488\n",
      "425 0.000814191629479\n",
      "426 0.000781864095846\n",
      "427 0.000750824788478\n",
      "428 0.000721027441509\n",
      "429 0.000692405460133\n",
      "430 0.000664917134249\n",
      "431 0.000638525432222\n",
      "432 0.000613186823886\n",
      "433 0.000588850808208\n",
      "434 0.00056548859207\n",
      "435 0.000543050884782\n",
      "436 0.000521505031962\n",
      "437 0.000500814476337\n",
      "438 0.000480951593966\n",
      "439 0.000461872506848\n",
      "440 0.000443557522997\n",
      "441 0.000425964948023\n",
      "442 0.000409070115226\n",
      "443 0.000392845410361\n",
      "444 0.000377265891183\n",
      "445 0.000362308591176\n",
      "446 0.000347947672472\n",
      "447 0.000334151565849\n",
      "448 0.000320902832413\n",
      "449 0.000308180680198\n",
      "450 0.00029596229156\n",
      "451 0.00028423002315\n",
      "452 0.000272970422382\n",
      "453 0.00026215137257\n",
      "454 0.000251762667556\n",
      "455 0.000241784153477\n",
      "456 0.000232202650462\n",
      "457 0.000223001338608\n",
      "458 0.000214169276067\n",
      "459 0.000205683592247\n",
      "460 0.00019753560049\n",
      "461 0.000189708791806\n",
      "462 0.00018219304306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463 0.000174978979797\n",
      "464 0.000168051778674\n",
      "465 0.000161396473428\n",
      "466 0.000155004495391\n",
      "467 0.000148865609739\n",
      "468 0.00014297001905\n",
      "469 0.000137308751531\n",
      "470 0.000131872916577\n",
      "471 0.000126652843159\n",
      "472 0.000121639255714\n",
      "473 0.000116823103321\n",
      "474 0.000112198156907\n",
      "475 0.000107757271015\n",
      "476 0.000103493013697\n",
      "477 9.93963061772e-05\n",
      "478 9.54630277221e-05\n",
      "479 9.1684806149e-05\n",
      "480 8.80558120381e-05\n",
      "481 8.45722022258e-05\n",
      "482 8.12265447498e-05\n",
      "483 7.80122571714e-05\n",
      "484 7.49256116606e-05\n",
      "485 7.19614408316e-05\n",
      "486 6.91143272994e-05\n",
      "487 6.63805660514e-05\n",
      "488 6.37550812975e-05\n",
      "489 6.12329283966e-05\n",
      "490 5.88112890844e-05\n",
      "491 5.6486015822e-05\n",
      "492 5.42518055844e-05\n",
      "493 5.21067893786e-05\n",
      "494 5.00462417468e-05\n",
      "495 4.80669222932e-05\n",
      "496 4.61660899884e-05\n",
      "497 4.43409103608e-05\n",
      "498 4.25877456651e-05\n",
      "499 4.09046668894e-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
